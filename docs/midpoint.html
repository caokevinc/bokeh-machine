<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
    div.padded {
      padding-top: 0px;
      padding-right: 100px;
      padding-bottom: 0.25in;
      padding-left: 100px;
    }
  </style>
<title>Kevin Cao  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Final Project Milestone - Bokeh Machine - Depth of Field Synthesizer</h1>
    <h2 align="middle">Kevin Cao, Angela Dong, Aniruddha Nrusimha </h2>

    <div class="padded">
        <p>
            We worked on three approaches to implmenting a depth map, each from
            a different paper. Our experiments have been giving us more intuition
            about the depth map problem, and should hopefully allow us to continue
            more productively.
        </p>

    <h3>Enhanced Image Gradients</h2>
        </p>
          We first tried a method from
          <a href="https://www.sciencedirect.com/science/article/pii/S1877050915031968"> this paper</a>
          that tries to find a depth map with gradients close to the original image gradient.
          The assumption is that the gradients in the depth map should match up
          to the gradients in the image. The paper suggests and error function
          relating the image gradient to the depth map gradients and provides a
          closed form solution for the depth map.
        </p>
        <div align="middle">
            <table style="width=100%">
              <tr valign="top">
                  <td align="left">
                  <img src="milestone-images/enhancedalgo.png" width="850" />
                  <figcaption align="middle">Algorithm for constructing Depth Map from Bala et. al</figcaption>
                </td>

            </table>
        </div>
          <div align="center">
              <table style="width=100%">
                <tr valign="top">
                    <td align="middle">
                    <img src="milestone-images/yq.png" width="480px" />
                    <figcaption align="middle">Original</figcaption>
                  </td>
                    <td align="middle">
                    <img src="milestone-images/enhanced.png" width="480px" />
                    <figcaption align="middle">Depth Map</figcaption>
                  </td>
              </table>
          </div>
        <p>
          However we found that this method gave us a weak, and frankly horrifying
          depth map. This, at least in its current implementation, is a dead end for us.
        </p>


      <h3>Defocus map estimation</h2>
        <div align="center">
            <table style="width=100%">
              <tr valign="top">
                  <td align="middle">
                  <img src="milestone-images/edgeblur.png" width="800px" />
                  <figcaption align="middle">Overview of blur estimation approach, taken from Zhuo et. al</figcaption>
                </td>
            </table>
        </div>
      <p>
          In this approach, we blur the image and take the ratio of the gradients
          of the original image with the gradients of the blurred image. This ratio
          gives us an estimation of the standard deviation of the original blur of a
          region of the image, as we model out of focus areas as a gaussian blur.
          This effectively gives us a "defocus map" which we can roughly equate to a
          depth map.
      </p>
      <div align="center">
          <table style="width=100%">
            <tr valign="top">
                <td align="middle">
                <img src="milestone-images/yq.png" width="480px" />
                <figcaption align="middle">Original</figcaption>
              </td>
              <td align="middle">
              <img src="milestone-images/diff.png" width="480px" />
              <figcaption align="middle">Ratio of original image gradient to blurred image gradient</figcaption>
            </td>

          </td>
          <td align="middle">
          <img src="milestone-images/canny.png" width="480px" />
          <figcaption align="middle">Canny Edge Detector Edge Map</figcaption>
        </td>
        </tr>
        <tr>
            <td align="middle">
            <img src="milestone-images/sparse.png" width="480px" />
            <figcaption align="middle">Sparse Defocus Map</figcaption>
          </td>
          </table>
      </div>
      <p>
        We can see in the sparse defocus map that edges in the foreground are lighter than
        those in the background. In this visualization, this means that the edges
        in the foreground have original blurs less than those in the background,
        and is a hopeful sign that we are on the right track.
      </p>
    <h3>Next Steps</h3>
    <p>
        Our next steps are to follow through with the Defocus map estimation method
        and finish interpolating from the sparse defocus map we have to a full
        defocus map using laplacian matting. We will also have to implement the thin
        lens model that we can use on the depth map once we have our completed depth map.
    </p>



    <h3> Resources </h3>
    <ol>
      <li>http://graphics.stanford.edu/papers/portrait/wadhwa-portrait-sig18.pdf - Google portrait mode paper
      <li>https://www.sciencedirect.com/science/article/pii/S1877050915031968 - Enhanced Image Gradients
      <li>https://www.comp.nus.edu.sg/~tsim/documents/defocusEstimation-published.pdf - Defocus map estimation from a single image
      <li>https://arxiv.org/pdf/1909.05483v1.pdf - 3d ken burns
      <li>https://arxiv.org/pdf/1810.08100.pdf - depth of field from single image
    </ol>





</div>
</body>
</html>
